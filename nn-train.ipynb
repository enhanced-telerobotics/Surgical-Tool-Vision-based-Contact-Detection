{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "\n",
    "import utils\n",
    "from VisionModels import CustomCNN, CustomEfficientNetB3\n",
    "from VisionDatasets import ContactDataset\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_json = os.path.join(os.getcwd(), 'settings/parameters.json')\n",
    "paths_json = os.path.join(os.getcwd(), 'settings/paths.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(parameters_json, 'r') as json_file:\n",
    "    params = json.load(json_file)\n",
    "\n",
    "with open(paths_json, 'r') as json_file:\n",
    "    paths = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = params[\"random_seed\"]\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = str(random_seed)\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = \":4096:8\"\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = [1, 3, 5, 7, 8, 10, 12, 14, 15, 17, 19, 21, 41, 98, 107, 143]\n",
    "val_set = [2, 4, 9, 11, 16, 18, 42, 116]\n",
    "test_set = [37, 68, 71, 23, 22, 24, 25, 26, 27, 28, 29,\n",
    "            46, 47, 38, 95, 104, 101, 92, 110, 45, 125, 134]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_combinations = list(product(['CustomCNN', 'EfficientNet'],\n",
    "                                  ['GT']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(paths['silicone']['labels'], header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the data rows by the index of sets\n",
    "train_data = data[data['HPC_Path'].str.extract(\n",
    "    r'imageset_(\\d+)').astype(int).isin(train_set).any(axis=1)]\n",
    "val_data = data[data['HPC_Path'].str.extract(\n",
    "    r'imageset_(\\d+)').astype(int).isin(val_set).any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# add data to Datasets\n",
    "train_dataset = ContactDataset(\n",
    "    images=[Image.open(image)\n",
    "            for image in train_data['HPC_Path'].tolist()],\n",
    "    labels=train_data['GT'].to_numpy(),\n",
    "    jitter=True)\n",
    "\n",
    "val_dataset = ContactDataset(\n",
    "    images=[Image.open(image)\n",
    "            for image in val_data['HPC_Path'].tolist()],\n",
    "    labels=val_data['GT'].to_numpy(),\n",
    "    jitter=False)\n",
    "\n",
    "# create DataLoader with existed Datasets\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=params['CustomCNN']['batch_size'],\n",
    "    pin_memory=True,\n",
    "    num_workers=(4 if os.cpu_count() > 4 else os.cpu_count()))\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=1024,\n",
    "    pin_memory=True)\n",
    "\n",
    "\n",
    "# set up loss function\n",
    "weights = train_dataset.getWeights().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss(weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, label_name in model_combinations:\n",
    "    # select the model\n",
    "    if model_name == 'CustomCNN':\n",
    "        model = CustomCNN()\n",
    "    elif model_name == 'EfficientNet':\n",
    "        model = CustomEfficientNetB3()\n",
    "\n",
    "    # set up the optimizer (hyper-parameters)\n",
    "    optimizer = optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=params[model_name]['learning_rate'],\n",
    "        weight_decay=params[model_name]['weight_decay'])\n",
    "\n",
    "    # train and retrieve the metrics\n",
    "    utils.train(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        loss_fn=loss_fn,\n",
    "        dataloader=train_dataloader,\n",
    "        val_dataloader=val_dataloader,\n",
    "        device=device,\n",
    "        use_tqdm=True,\n",
    "        epochs=params['epochs'])\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%H%M%S\")\n",
    "    with open(f'results/metrics_{model_name}_{timestamp}.json', 'w') as f:\n",
    "        json.dump(model.metrics, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomCNN()\n",
    "model_name = 'CustomCNN'\n",
    "\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=params[model_name]['learning_rate'],\n",
    "    weight_decay=params[model_name]['weight_decay'])\n",
    "\n",
    "utils.train(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    loss_fn=loss_fn,\n",
    "    dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    device=device,\n",
    "    use_tqdm=True,\n",
    "    epochs=10)\n",
    "\n",
    "# Get the current time and format it as a string\n",
    "timestamp = datetime.now().strftime(\"%H%M%S\")\n",
    "\n",
    "with open(f'results/metrics_{model_name}_{timestamp}.json', 'w') as f:\n",
    "    json.dump(model.metrics, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current time and format it as a string\n",
    "now = datetime.now()\n",
    "timestamp = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "with open(f'results/metrics_{timestamp}.json', 'w') as f:\n",
    "    json.dump(model.metrics, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = utils.predict(model=model,\n",
    "                     dataloader=val_dataloader,\n",
    "                     device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(val_data['GT'].to_numpy())\n",
    "print(pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
