{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss and Accuracy over Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "from itertools import cycle\n",
    "\n",
    "\n",
    "def loss_plot(xlim: (int, int) = None):\n",
    "    # Use glob to find all json files in the specified directory\n",
    "    file_list = glob.glob('results/metrics_*.json')\n",
    "\n",
    "    # Create a color cycle iterator to assign unique colors\n",
    "    color_cycle = cycle(plt.rcParams['axes.prop_cycle'].by_key()['color'])\n",
    "\n",
    "    # Plot the data\n",
    "    plt.figure(figsize=(14, 7))\n",
    "\n",
    "    # Initialize a dictionary to store colors for each label\n",
    "    color_map = {}\n",
    "\n",
    "    # Subplot for Loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for file in file_list:\n",
    "        # Extract model_name and label_name from the file name\n",
    "        filename = os.path.basename(file)\n",
    "        model_label = filename.replace('metrics_', '').rsplit('.', 1)[0]\n",
    "\n",
    "        # Check if we have already assigned a color, otherwise get the next color\n",
    "        if model_label not in color_map:\n",
    "            color_map[model_label] = next(color_cycle)\n",
    "\n",
    "        # Read json content\n",
    "        with open(file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        epochs = list(range(1, len(data['train_loss']) + 1))\n",
    "        plt.plot(epochs, data['train_loss'], label=f'{model_label}',\n",
    "                 color=color_map[model_label])\n",
    "        if len(data['val_acc']) > 0:\n",
    "            plt.plot(epochs, data['val_loss'], linestyle='--', color=color_map[model_label])\n",
    "\n",
    "    plt.title('Loss over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlim(xlim)\n",
    "\n",
    "    # Subplot for Accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    for file in file_list:\n",
    "        # Extract model_name and label_name from the file name\n",
    "        filename = os.path.basename(file)\n",
    "        model_label = filename.replace('metrics_', '').rsplit('.', 1)[0]\n",
    "\n",
    "        # Read json content\n",
    "        with open(file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        epochs = list(range(1, len(data['train_acc']) + 1))\n",
    "        plt.plot(epochs, data['train_acc'], label=f'{model_label}',\n",
    "                 color=color_map[model_label])\n",
    "        if len(data['val_acc']) > 0:\n",
    "            plt.plot(epochs, data['val_acc'], linestyle='--', color=color_map[model_label])\n",
    "\n",
    "    plt.title('Accuracy over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "\n",
    "    # 添加自定义图例\n",
    "    custom_lines = [plt.Line2D([0], [0], color='black', lw=2),\n",
    "                    plt.Line2D([0], [0], color='black', lw=2, linestyle='--')]\n",
    "    plt.figlegend(custom_lines, ['Train', 'Val'], loc='lower center', ncol=2)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.legend()\n",
    "    plt.xlim(xlim)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "loss_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "start_epoch = 0\n",
    "\n",
    "file_list = glob.glob('results/metrics_*.json')\n",
    "for file in file_list:\n",
    "    with open(file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    print(file)\n",
    "    print(int(np.argmin(data['val_loss'][start_epoch:]))+start_epoch)\n",
    "    print(int(np.argmax(data['val_acc'][start_epoch:]))+start_epoch)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show cropped images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "from VisionDatasets import ContactDataset\n",
    "from PIL import Image, ImageDraw\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "paths_json = os.path.join(os.getcwd(), 'settings/paths.json')\n",
    "with open(paths_json, 'r') as json_file:\n",
    "    paths = json.load(json_file)\n",
    "\n",
    "data = pd.read_csv(paths['silicone']['labels'], header=0).sample(n=12)\n",
    "\n",
    "dataset = ContactDataset(\n",
    "    images=data['HPC_Path'].tolist(),\n",
    "    labels=data['GT'].to_numpy(),\n",
    "    coords=list(zip(\n",
    "        data['x'].astype(int),\n",
    "        data['y'].astype(int))),\n",
    "    jitter=False)\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=1024,\n",
    "    pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "width, height = 936, 702\n",
    "merged_image = Image.new('RGB', (width, height))\n",
    "\n",
    "draw = ImageDraw.Draw(merged_image)\n",
    "\n",
    "small_image_width, small_image_height = 234, 234\n",
    "x, y = 0, 0\n",
    "\n",
    "for images, labels in dataloader:\n",
    "    for image in images:\n",
    "        image = torchvision.transforms.ToPILImage()(image)\n",
    "        merged_image.paste(image, (x, y))\n",
    "    \n",
    "        x += small_image_width\n",
    "        \n",
    "        if x + small_image_width > width:\n",
    "            x = 0\n",
    "            y += small_image_height\n",
    "\n",
    "merged_image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model_set = ['CustomCNN', 'EfficientNet']\n",
    "label_set = ['MTurk']\n",
    "model_combinations = list(product(model_set, label_set))\n",
    "test_set = [37, 68, 71, 23, 22, 24, 25, 26, 27, 28, 29,\n",
    "            46, 47, 38, 95, 104, 101, 92, 110, 45, 125, 134]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('labels/silicone_20231113_040138.pkl', 'rb') as file:\n",
    "    results = pickle.load(file)\n",
    "\n",
    "\n",
    "for set_name in test_set:\n",
    "    data = {\n",
    "        'gt': None,\n",
    "        'pred': {},\n",
    "        'binary_predictions': {}\n",
    "    }\n",
    "    # Process the data for each model and label combination\n",
    "    for model_name, label_name in model_combinations:\n",
    "        pred, gt = results[(model_name, label_name, set_name)].values()\n",
    "        binary_predictions = (pred > 0.5).astype(int)\n",
    "\n",
    "        # Store ground truth only once as it's the same for all combinations\n",
    "        if data['gt'] is None:\n",
    "            data['gt'] = gt\n",
    "\n",
    "        # Store predictions and binary predictions\n",
    "        data['pred'][f'{model_name}-{label_name}'] = pred\n",
    "        data['binary_predictions'][f'{model_name}-{label_name}'] = binary_predictions\n",
    "\n",
    "    \n",
    "    colors = plt.cm.get_cmap('Set1', len(data['pred']))\n",
    "\n",
    "    # Convert indices to time (assuming a sampling rate of 30Hz)\n",
    "    sampling_rate_hz = 30\n",
    "    time = np.arange(len(data['gt'])) / sampling_rate_hz\n",
    "\n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot ground truth\n",
    "    plt.plot(time, data['gt'], label='Ground Truth', color='black')\n",
    "\n",
    "    # Plot predictions and binary predictions\n",
    "    for i, key in enumerate(data['pred']):\n",
    "        color = colors(i)\n",
    "        plt.plot(time, data['pred'][key], label=f'Pred - {key}', alpha=0.7, linestyle='--', color=color)\n",
    "        plt.plot(time, data['binary_predictions'][key], label=f'Binary Pred - {key}', alpha=0.7, color=color)\n",
    "\n",
    "    plt.title(f'Predictions and Ground Truth over Time on {set_name}')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Predictions')\n",
    "    plt.legend()\n",
    "    plt.xlim(25, 50)\n",
    "    plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.1), shadow=True, ncol=3)\n",
    "    plt.savefig(f'plots/{set_name}.pdf',\n",
    "            format='pdf', bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add coordinates to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_json = os.path.join(os.getcwd(), 'settings/paths.json')\n",
    "with open(paths_json, 'r') as json_file:\n",
    "    paths = json.load(json_file)\n",
    "\n",
    "model_root = f'/home/{os.getlogin()}/ERIE/realistic/Track-Shuyuan-2023-08-13/videos'\n",
    "model_name = 'DLC_resnet50_TrackAug13shuffle1_70000'\n",
    "\n",
    "training_sets = [\"M1_L_V1_1\", \"M1_L_V1_2\", \"M1_R_V1_1\", \"M1_R_V1_2\",\n",
    "                 \"M3_L_V1_1\", \"M3_L_V1_2\", \"M3_R_V1_1\", \"M3_R_V1_2\",\n",
    "                 \"M5_L_V1_1\", \"M5_L_V1_2\", \"M5_R_V1_1\", \"M5_R_V1_2\"]\n",
    "test_sets = [\"M1_L_V2_1\", \"M1_L_V2_2\", \"M1_R_V2_1\", \"M1_R_V2_2\",\n",
    "             \"M3_L_V2_1\", \"M3_L_V2_2\", \"M3_R_V2_1\", \"M3_R_V2_2\",\n",
    "             \"M5_L_V2_1\", \"M5_L_V2_2\", \"M5_R_V2_1\", \"M5_R_V2_2\",\n",
    "             \"M2_L_V1_1\", \"M2_L_V1_2\", \"M2_R_V1_1\", \"M2_R_V1_2\",\n",
    "             \"M4_L_V1_1\", \"M4_L_V1_2\", \"M4_R_V1_1\", \"M4_R_V1_2\",\n",
    "             \"M2_L_V2_1\", \"M2_L_V2_2\", \"M2_R_V2_1\", \"M2_R_V2_2\",\n",
    "             \"M4_L_V2_1\", \"M4_L_V2_2\", \"M4_R_V2_1\", \"M4_R_V2_2\"]\n",
    "\n",
    "data = pd.read_csv(paths['realistic']['labels'], header=0)\n",
    "\n",
    "coordinates = {}\n",
    "\n",
    "for dataset in training_sets + test_sets:\n",
    "    coordinates[dataset] = pd.read_hdf(\n",
    "        os.path.join(model_root, f'{dataset}_L_h264{model_name}.h5')).loc[:, [\n",
    "            ('DLC_resnet50_TrackAug13shuffle1_70000', 'Mid_1', 'x'),\n",
    "            ('DLC_resnet50_TrackAug13shuffle1_70000', 'Mid_1', 'y')]].to_numpy()\n",
    "    \n",
    "def extract_id(img_filename):\n",
    "    return int(img_filename.split('_')[1].split('.')[0])\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    dataset = row['dataset']\n",
    "    img_num = row['image']\n",
    "    id = extract_id(img_num)\n",
    "    \n",
    "    x, y = coordinates[dataset][id]\n",
    "    data.at[index, 'x'] = x\n",
    "    data.at[index, 'y'] = y\n",
    "\n",
    "data.to_csv(paths['realistic']['labels'], index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag Data Time Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "test_set = ['C_M1_T1_8', 'M1_NF']\n",
    "\n",
    "\n",
    "data_set = 'silicone'\n",
    "for set_name in test_set:\n",
    "    # concat paths\n",
    "    label_path = os.path.join(\n",
    "        f'/home/sxy841/ERIE/{data_set}/output', f'{set_name}', 'labels_30hz.txt')\n",
    "    nn_label_path = os.path.join(\n",
    "        f'/home/sxy841/ERIE/{data_set}/nn-pose/labels', f'{set_name}_gnn.txt')\n",
    "\n",
    "    nn_positions = pd.read_csv(nn_label_path, header=None).to_numpy()\n",
    "    positions = pd.read_csv(\n",
    "        label_path, header=None).iloc[:, 7:10].to_numpy()\n",
    "    desired_positions = pd.read_csv(\n",
    "        label_path, header=None).iloc[:, 14:17].to_numpy()\n",
    "    pos_diff = desired_positions-positions\n",
    "    psm_force = pd.read_csv(\n",
    "        label_path, header=None).iloc[:, 62:65].to_numpy()\n",
    "    force = pd.read_csv(\n",
    "        label_path, header=None).iloc[:, 1:4].to_numpy()\n",
    "    \n",
    "    gt_labels = []\n",
    "    force_threshold = 0.2\n",
    "    for row in force:\n",
    "        gt_labels.append(True if np.sqrt(row.dot(row)) > force_threshold else False)\n",
    "\n",
    "    # Plotting\n",
    "    fig, axs = plt.subplots(3, figsize=(10, 15))\n",
    "    \n",
    "    print(set_name)\n",
    "\n",
    "    # X, Y, Z components of positions\n",
    "    for i in range(3):\n",
    "        # axs[i].plot(positions[:, i],force[:,i], label='Actual Position')\n",
    "        # axs[i].plot(positions[:, i],2000*pos_diff[:,i], '.' ,label='Actual Position')\n",
    "        # axs[i].plot(1000*pos_diff[:,i], '.' ,label='PosDiff')\n",
    "        axs[i].plot(positions[:, i], label='Actual Position')\n",
    "        # axs[i].plot(force[:, i], label='Force')\n",
    "        # axs[i].plot(psm_force[:, i], label='PSM Force')\n",
    "        # axs[i].plot(nn_positions[:,i],label='NN Position')\n",
    "        # axs[i].plot(desired_positions[:, i], label='Desired Position')\n",
    "        axs[i].set_title(f'Component {i+1} (X, Y, Z respectively)')\n",
    "        axs[i].legend()\n",
    "        axs[i].set_xlim(0,1000)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "test_set = ['C_M1_T1_8', 'M1_NF']\n",
    "\n",
    "\n",
    "data_set = 'silicone'\n",
    "for set_name in test_set:\n",
    "    # concat paths\n",
    "    label_path = os.path.join(\n",
    "        f'/home/sxy841/ERIE/{data_set}/output', f'{set_name}', 'labels_30hz.txt')\n",
    "    nn_label_path = os.path.join(\n",
    "        f'/home/sxy841/ERIE/{data_set}/nn-pose/labels', f'{set_name}_gnn.txt')\n",
    "\n",
    "    nn_positions = pd.read_csv(nn_label_path, header=None).to_numpy()\n",
    "    positions = pd.read_csv(\n",
    "        label_path, header=None).iloc[:, 7:10].to_numpy()\n",
    "    desired_positions = pd.read_csv(\n",
    "        label_path, header=None).iloc[:, 14:17].to_numpy()\n",
    "    pos_diff = desired_positions-positions\n",
    "    psm_force = pd.read_csv(\n",
    "        label_path, header=None).iloc[:, 62:65].to_numpy()\n",
    "    force = pd.read_csv(\n",
    "        label_path, header=None).iloc[:, 1:4].to_numpy()\n",
    "    \n",
    "    gt_labels = []\n",
    "    force_threshold = 0.2\n",
    "    for row in force:\n",
    "        gt_labels.append(True if np.sqrt(row.dot(row)) > force_threshold else False)\n",
    "\n",
    "    psm_force = MinMaxScaler().fit_transform(psm_force[gt_labels])\n",
    "    positions = MinMaxScaler().fit_transform(positions[gt_labels])\n",
    "    force = MinMaxScaler().fit_transform(force[gt_labels])\n",
    "    \n",
    "\n",
    "    # Plotting\n",
    "    fig, axs = plt.subplots(3, figsize=(10, 15))\n",
    "    \n",
    "    print(set_name)\n",
    "\n",
    "    # X, Y, Z components of positions\n",
    "    for i in range(3):\n",
    "        # axs[i].plot(positions[:, i],force[:,i], label='Actual Position')\n",
    "        # axs[i].plot(positions[:, i],2000*pos_diff[:,i], '.' ,label='Actual Position')\n",
    "        # axs[i].plot(1000*pos_diff[:,i], '.' ,label='PosDiff')\n",
    "        axs[i].plot(positions[:, i], label='Actual Position')\n",
    "        axs[i].plot(force[:, i], label='Force')\n",
    "        # axs[i].plot(psm_force[:, i], label='PSM Force')\n",
    "        # axs[i].plot(nn_positions[:,i],label='NN Position')\n",
    "        # axs[i].plot(desired_positions[:, i], label='Desired Position')\n",
    "        axs[i].set_title(f'Component {i+1} (X, Y, Z respectively)')\n",
    "        axs[i].legend()\n",
    "        axs[i].set_xlim(0,1000)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
